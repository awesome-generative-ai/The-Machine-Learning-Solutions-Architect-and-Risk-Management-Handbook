{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0691774",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f55a04f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 pip3 工具升级 TensorFlow 库到最新版本，并覆盖之前安装的版本。\n",
    "! pip3 install --upgrade tensorflow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f9507f",
   "metadata": {},
   "source": [
    "**解释：**\n",
    "\n",
    "这段代码使用命令行工具 `pip3` 升级 TensorFlow 库到最新版本，并覆盖之前安装的版本。\n",
    "\n",
    "* **`!`：** 表示在当前 Python 环境中执行系统命令，而不是 Python 代码。\n",
    "* **`pip3`：** Python 的包管理工具，用于安装、升级和管理 Python 库。\n",
    "* **`install`：**  表示安装 Python 库。\n",
    "* **`--upgrade`：**  表示升级 Python 库到最新版本。\n",
    "* **`tensorflow`：**  一个广泛应用的开源机器学习库，主要用于深度学习，包含了多种神经网络模型结构、数据加载器、训练优化器和评估工具等。\n",
    "\n",
    "这段代码的主要目的是确保使用最新版本的 TensorFlow 库，以获得最新的功能、性能改进以及 bug 修复。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab3e3b2",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 NumPy 库，它提供了数组、矩阵和其他数学运算工具。\n",
    "import numpy as np \n",
    "\n",
    "# 导入 TensorFlow 库，一个用于机器学习和深度学习的开源库。\n",
    "import tensorflow as tf  \n",
    "\n",
    "# 加载 FashionMNIST 数据集，并将其存储在 train 和 test 变量中。\n",
    "train, test = tf.keras.datasets.fashion_mnist.load_data() \n",
    "\n",
    "# 从 train 数据集取出图像数据和标签数据，分别存储在 images 和 labels 变量中。\n",
    "images, labels = train \n",
    "\n",
    "# 将标签数据转换为整数类型。\n",
    "labels = labels.astype(np.int32) \n",
    "\n",
    "# 将图像数据进行归一化处理，将其数值范围缩放到 0 到 1 之间。\n",
    "images = images/256    \n",
    "\n",
    "# 使用 TensorFlow 的 tf.data.Dataset.from_tensor_slices 函数创建一个数据集，并加载图像数据和标签数据。\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((images, labels)) \n",
    "\n",
    "# 使用 batch 方法将数据集划分为 batch，每个 batch 包含 32 个样本。\n",
    "train_ds = train_ds.batch(32) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8c4bf3",
   "metadata": {},
   "source": [
    "**解释：**\n",
    "\n",
    "这段代码完成了以下几件事：\n",
    "\n",
    "1. **导入库：** 导入 `numpy` 和 `tensorflow` 库，并使用 `tf.keras.datasets.fashion_mnist.load_data()` 加载 FashionMNIST 数据集。\n",
    "2. **准备数据：** 从加载的数据集中提取图像数据和标签数据。\n",
    "3. **数据预处理：** 将标签转换为整数类型，并对图像数据进行归一化处理。\n",
    "4. **创建数据集：** 使用 `tf.data.Dataset.from_tensor_slices` 创建一个 TensorFlow 数据集，并使用 `batch` 方法将数据划分为 batch。\n",
    "\n",
    "这段代码主要作用是准备 MNIST 数据集，以便用于后续的模型训练。它完成了数据加载、预处理和数据集创建等步骤，为后续模型训练提供了必要的准备工作。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bc7736",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 Matplotlib 库，它提供了一个用于创建静态、交互式和动画绘图的工具包。\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "# 打印第一个样本的标签。\n",
    "print (\"标签:\" + str(labels[0])) \n",
    "\n",
    "# 从图像数据中取出第一个图像。\n",
    "pixels = images[0] \n",
    "\n",
    "# 使用 Matplotlib 绘制图像，并使用灰度色板。\n",
    "plt.imshow(pixels, cmap='gray') \n",
    "\n",
    "# 显示图像。\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fd5761",
   "metadata": {},
   "source": [
    "**解释：**\n",
    "\n",
    "这段代码展示了 FashionMNIST 数据集中的第一个图像，并打印了该图像的标签。\n",
    "\n",
    "* **`from matplotlib import pyplot as plt`：**  导入 Matplotlib 库并使用 `plt` 作为别名，方便后续调用 Matplotlib 库中的函数。\n",
    "* **`print (\"标签:\" + str(labels[0]))`：**  打印第一个样本的标签。`labels[0]` 获取了 `labels` 数组中的第一个元素，即第一个图像的标签。\n",
    "* **`pixels = images[0]`：**  从 `images` 数组中取出第一个图像，并将它存储在 `pixels` 变量中。\n",
    "* **`plt.imshow(pixels, cmap='gray')`：**  使用 Matplotlib 的 `imshow` 函数绘制图像，并使用 `cmap='gray'` 指定使用灰度色板。\n",
    "* **`plt.show()`：**  显示图像。\n",
    "\n",
    "这段代码演示了如何使用 Matplotlib 可视化 FashionMNIST 数据集中的一個图像，通过展示图像以及对应标签，可以让用户直观地理解数据内容。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7ccc58",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 TensorFlow 的 tf.keras.Sequential 类定义一个神经网络模型，包含了以下几层：\n",
    "model = tf.keras.Sequential([ \n",
    "\n",
    "   # Flatten 层，将输入数据展平成一维向量。\n",
    "   tf.keras.layers.Flatten(), \n",
    "\n",
    "   # 第一层密集连接层，包含 100 个神经元，使用 ReLU 激活函数。\n",
    "   tf.keras.layers.Dense(100, activation=\"relu\"), \n",
    "\n",
    "   # 第二层密集连接层，包含 50 个神经元，使用 ReLU 激活函数。\n",
    "   tf.keras.layers.Dense(50, activation=\"relu\"), \n",
    "\n",
    "   # 第三层密集连接层，包含 10 个神经元，对应 FashionMNIST 数据集的 10 个类别。\n",
    "   tf.keras.layers.Dense(10), \n",
    "\n",
    "   # Softmax 层，将模型的输出转换为概率分布，并预测每个类别的概率。\n",
    "   tf.keras.layers.Softmax() \n",
    "\n",
    "]) \n",
    "\n",
    "# 使用 compile 方法配置模型的训练参数，包括优化器、损失函数和评估指标。\n",
    "model.compile(optimizer='adam', \n",
    "\n",
    "              # 使用 SparseCategoricalCrossentropy 作为损失函数，用于计算模型输出与真实标签之间的交叉熵损失。\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),  \n",
    "\n",
    "              # 使用 SparseCategoricalAccuracy 作为评估指标，用于评估模型的准确率。\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]) \n",
    "\n",
    "# 使用 fit 方法训练模型，训练 10 个 epochs。\n",
    "model.fit(train_ds, epochs=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f6d43d",
   "metadata": {},
   "source": [
    "**解释：**\n",
    "\n",
    "这段代码定义了一个简单的多层感知器（MLP）模型，并使用 TensorFlow 进行训练。\n",
    "\n",
    "1. **定义模型：** 使用 `tf.keras.Sequential` 类定义了一个包含四个密集连接层和一个 Softmax 层的 Sequential 模型。\n",
    "    * `tf.keras.layers.Flatten()`： 将输入图像数据展平成一维向量，以便输入到密集连接层。\n",
    "    * `tf.keras.layers.Dense(100, activation=\"relu\")`： 定义第一个密集连接层，包含 100 个神经元，使用 ReLU 激活函数。\n",
    "    * `tf.keras.layers.Dense(50, activation=\"relu\")`： 定义第二个密集连接层，包含 50 个神经元，使用 ReLU 激活函数。\n",
    "    * `tf.keras.layers.Dense(10)`： 定义第三个密集连接层，包含 10 个神经元，对应 FashionMNIST 数据集的 10 个类别。\n",
    "    * `tf.keras.layers.Softmax()`：  将模型的输出转换为概率分布，并预测每个类别的概率。\n",
    "2. **配置模型：**  使用 `compile` 方法配置模型的训练参数。\n",
    "    * `optimizer='adam'`：  使用 Adam 作为优化器，Adam 是一种常用的优化算法。\n",
    "    * `tf.keras.losses.SparseCategoricalCrossentropy()`：  使用 SparseCategoricalCrossentropy 作为损失函数，用于计算模型输出与真实标签之间的交叉熵损失。\n",
    "    * `tf.keras.metrics.SparseCategoricalAccuracy()`：  使用 SparseCategoricalAccuracy 作为评估指标，用于评估模型的准确率。\n",
    "3. **训练模型：**  使用 `fit` 方法训练模型 10 个 epochs。\n",
    "\n",
    "这段代码演示了如何在 TensorFlow中定义并训练一个简单的 MLP 模型。模型的结构简单，并使用默认的训练参数进行训练。 用户可以根据需求调整模型结构、训练参数和训练数据，从而实现期望的预测结果。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0a8a35",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从 test 数据集中取出图像数据和标签数据，分别存储在 images_test 和 labels_test 变量中。\n",
    "images_test, labels_test = test \n",
    "\n",
    "# 将标签数据转换为整数类型。\n",
    "labels_test = labels_test.astype(np.int32) \n",
    "\n",
    "# 将图像数据进行归一化处理，将其数值范围缩放到 0 到 1 之间。\n",
    "images_test = images_test/256    \n",
    "\n",
    "# 使用 TensorFlow 的 tf.data.Dataset.from_tensor_slices 函数创建一个数据集，并加载图像数据和标签数据。\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((images_test, labels_test)) \n",
    "\n",
    "# 使用 batch 方法将数据集划分为 batch，每个 batch 包含 32 个样本。\n",
    "test_ds = train_ds.batch(32) \n",
    "\n",
    "# 使用 shuffle 方法将数据集进行随机打乱，打乱顺序的缓冲区大小为 30。\n",
    "test_ds = train_ds.shuffle(30) \n",
    "\n",
    "# 使用 model.evaluate 方法评估模型在测试集上的性能，并获取损失值和准确率等结果。\n",
    "results = model.evaluate(test_ds) \n",
    "\n",
    "# 打印测试集上的损失值和准确率。\n",
    "print(\"测试集上的损失值（loss）和准确率（acc）:\", results) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adc0a54",
   "metadata": {},
   "source": [
    "**解释：**\n",
    "\n",
    "这段代码使用测试集评估训练好的模型，并打印模型在测试集上的损失值和准确率。\n",
    "\n",
    "1. **准备测试集：** 从加载的数据集中提取测试集的图像数据和标签数据。\n",
    "2. **数据预处理：** 对测试集数据进行与训练数据相同的数据预处理。\n",
    "3. **创建测试集数据集：** 使用 `tf.data.Dataset.from_tensor_slices` 创建一个 TensorFlow 数据集，并使用 `batch` 和 `shuffle` 方法将数据划分为 batch 并随机打乱。\n",
    "4. **评估模型：** 使用 `model.evaluate` 方法评估模型在测试集上的性能，并获取损失值和准确率等结果。\n",
    "5. **打印结果：** 打印测试集上的损失值和准确率。\n",
    "\n",
    "这段代码演示了如何使用 TensorFlow 评估模型在测试集上的性能，并使用 `model.evaluate` 方法计算模型的损失值和准确率，以便评估模型的泛化能力。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d29ed1f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用模型对测试集的图像数据进行预测，并获得预测结果。\n",
    "predictions = model.predict(test[0]) \n",
    "\n",
    "# 获取预测结果中每个样本的类别概率的最大值对应的类别索引，作为预测的标签。\n",
    "predicted_labels = np.argmax(predictions, axis=1) \n",
    "\n",
    "# 创建一个 TensorFlow 准确率指标对象。\n",
    "m = tf.keras.metrics.Accuracy() \n",
    "\n",
    "# 使用 update_state 方法更新准确率指标对象，将预测标签和真实标签传入以计算准确率。\n",
    "m.update_state(predicted_labels, test[1]) \n",
    "\n",
    "# 获取准确率指标的结果，并将其转换为 numpy 数组。\n",
    "m.result().numpy() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252aba7f",
   "metadata": {},
   "source": [
    "**解释：**\n",
    "\n",
    "这段代码使用训练好的模型对测试集进行预测，并计算模型在测试集上的准确率。\n",
    "\n",
    "1. **预测类别：** 使用训练好的模型 `model` 对测试集图像数据 `test[0]` 进行预测，并获得预测结果 `predictions`。每个预测结果是一个长度为 10 的数组，代表每个类别的概率。\n",
    "2. **获得预测标签：** 使用 `np.argmax` 获取每个预测结果中概率最大的类别索引，作为预测的标签，并将预测的标签存储在 `predicted_labels` 变量中。\n",
    "3. **计算准确率：** 创建一个 TensorFlow 准确率指标对象 `m`。使用 `update_state` 方法更新准确率指标对象，将预测标签 `predicted_labels` 和真实标签 `test[1]` 传入以计算准确率。最后使用 `m.result().numpy()` 获取准确率指标的结果，并将其转换为 Numpy 数组。\n",
    "\n",
    "\n",
    "这段代码演示了如何使用 TensorFlow 计算模型在测试集上的准确率。这个过程包含了预测类别、获取预测标签以及计算准确率指标，从而评估模型的性能。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffb39b0",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 TensorFlow 的 model.save 方法将训练好的模型保存到指定路径，模型文件名为 'my_model.keras'。\n",
    "model.save(\"my_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9a9fc9",
   "metadata": {},
   "source": [
    "**解释：**\n",
    "\n",
    "这段代码使用 TensorFlow 的 `model.save` 方法将训练好的模型 `model` 保存到磁盘上，以便在未来需要使用时加载并使用。\n",
    "\n",
    "* **`model.save` 方法：**  TensorFlow 中的每个 `tf.keras` 模型都拥有一个名为 `save` 的方法，可以用于将训练好的模型保存到磁盘。\n",
    "* **`\"my_model.keras\"`：** 是保存模型的路径和文件名，这里将模型保存到当前目录下，文件名叫做 `my_model.keras`。`keras` 是 TensorFlow 模型的常用后缀名。\n",
    "\n",
    "通过使用 `model.save` 方法保存模型，开发者就可以在之后需要使用模型的时候，使用 TensorFlow 提供的 `tf.keras.models.load_model` 函数加载模型，并在新的任务中使用该模型进行预测或进一步的训练。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca99445",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
