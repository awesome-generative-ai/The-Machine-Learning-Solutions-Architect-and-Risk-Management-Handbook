{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a986eee7",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2203e78d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装 PyTorch 库，这是一个用于机器学习的开源库，包含了张量计算、自动微分和神经网络构建等功能。\n",
    "!pip3 install torch \n",
    "\n",
    "# 安装 torchvision 库，它包含了预先训练好的模型、数据加载器和各种图像处理工具。\n",
    "!pip3 install torchvision "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8d673",
   "metadata": {},
   "source": [
    "**解释：**\n",
    "\n",
    "这段代码使用 `!pip3 install` 命令安装了两个 Python 库：`torch` 和 `torchvision`。这两个库都是用于深度学习的工具，它们提供了丰富的功能，可以帮助开发者轻松地构建、训练和部署神经网络模型。\n",
    "\n",
    "* **`torch`** 是 PyTorch 的核心库，它提供了一个强大的张量计算引擎，支持自动微分和神经网络构建功能。PyTorch 尤其适合灵活的深度学习研究，它允许开发者在运行时修改模型的结构，并轻松地调试神经网络。\n",
    "* **`torchvision`** 是一个与 `torch` 搭配使用的库，它包含了预先训练好的模型（如 ResNet、VGG 等），数据加载器，以及各种图像处理工具（如数据转换、图像增强等）。`torchvision` 简化了图像数据集的准备工作，并提供了可以立即使用的模型，方便开发者快速构建和测试深度学习应用。\n",
    "\n",
    "这段代码的主要作用是安装 PyTorch 和 torchvision，为后续的深度学习开发做好准备。开发者可以利用 PyTorch 的张量计算能力和 torchvision 提供的预训练模型和工具来高效地进行图像处理、模型训练和部署等任务。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ad23e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 NumPy 库，它提供了数组、矩阵和其他数学运算工具。\n",
    "import numpy as np \n",
    "\n",
    "# 导入 Matplotlib 库，它提供了绘图工具，可以用来可视化数据。\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# 导入 PyTorch 库，它提供了张量计算、自动微分和神经网络构建等功能。\n",
    "import torch \n",
    "\n",
    "# 导入 torchvision 库，它包含了预先训练好的模型、数据加载器和各种图像处理工具。\n",
    "from torchvision import datasets, transforms \n",
    "\n",
    "# 导入 PyTorch 的 nn 和 optim 模块，它们分别提供神经网络构建和优化器工具。\n",
    "from torch import nn, optim \n",
    "\n",
    "# 定义数据预处理流程，包括将图像转换为张量，并进行归一化。\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,),)]) \n",
    "\n",
    "# 加载 MNIST 训练数据集，将其存储到 'pytorch_data/train/' 目录中，下载数据集，并使用定义的数据预处理流程。\n",
    "trainset = datasets.MNIST('pytorch_data/train/', download=True, train=True, transform=transform) \n",
    "\n",
    "# 加载 MNIST 验证数据集，将其存储到 'pytorch_data/test/' 目录中，下载数据集，并使用定义的数据预处理流程。\n",
    "valset = datasets.MNIST('pytorch_data/test/', download=True, train=False, transform=transform) \n",
    "\n",
    "# 创建一个数据加载器，用于将训练数据集以 batch 为单位加载到模型中，其中 batch_size 为 64，并启用数据随机打乱。\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca8e9f6",
   "metadata": {},
   "source": [
    "**解释：**\n",
    "\n",
    "这段代码主要完成了以下几件事：\n",
    "\n",
    "1. **导入必要的库：** 导入 NumPy、Matplotlib、PyTorch 和 torchvision 库，并导入 PyTorch 的 nn 和 optim 模块。这些库提供了深度学习模型构建、数据预处理、模型训练、数据可视化等功能。\n",
    "2. **定义数据变换：** 使用 `transforms.Compose` 定义了一个数据变换流程，包括将图像转换为张量，并进行归一化处理。这将使得后续的模型训练更高效。\n",
    "3. **加载 MNIST 数据集：**  使用`datasets.MNIST` 加载 MNIST 手写数字数据集，并将数据集存储到指定的目录中。代码分别加载训练集和验证集，并使用之前定义的数据变换进行预处理。\n",
    "4. **创建数据加载器：** 使用 `torch.utils.data.DataLoader` 创建一个数据加载器，它会以 batch 为单位将训练集加载到模型中，并使用 `shuffle=True` 随机打乱数据，以提高模型泛化能力。\n",
    "\n",
    "这段代码完成了一些深度学习任务的预备工作，包括导入关键库、准备数据集、创建数据加载器等，并准备好了将数据喂给模型进行训练。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802ee5dc",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个神经网络模型，使用 PyTorch 的 nn.Sequential 模块来构建一个多层感知机（MLP）模型。\n",
    "model = nn.Sequential(\n",
    "    # 第一个线性层，将 784 维的输入数据映射到 128 维的输出。\n",
    "    nn.Linear(784, 128), \n",
    "\n",
    "    # ReLU 激活函数，将负值映射为 0，并将正值保持不变。\n",
    "    nn.ReLU(), \n",
    "\n",
    "    # 第二个线性层，将 128 维的输入数据映射到 64 维的输出。\n",
    "    nn.Linear(128, 64), \n",
    "\n",
    "    # 再次使用 ReLU 激活函数。\n",
    "    nn.ReLU(), \n",
    "\n",
    "    # 第三个线性层，将 64 维的输入数据映射到 10 维的输出，对应 MNIST 数据集的 10 个类别。\n",
    "    nn.Linear(64, 10)\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853f552e",
   "metadata": {},
   "source": [
    "**解释：**\n",
    "\n",
    "这段代码使用 `nn.Sequential` 模块定义了一个包含三个线性层和两个 ReLU 激活函数的多层感知器 (MLP) 模型，用于识别 MNIST 手写数字数据集中的 10 个类别。\n",
    "\n",
    "* **`nn.Sequential` 模块：**  它是 PyTorch 中常用的模块，用于构建神经网络模型。它接收一个层列表作为参数，并按顺序将这些层连接起来，形成一个完整的网络结构。\n",
    "* **`nn.Linear` 模块：** 用于定义线性层，它将输入数据与权重矩阵相乘并加上偏置项，实现线性变换。第一个线性层将 784 维的输入数据（MNIST 图像展开后的像素数据）映射到 128 维的输出，第二个线性层将 128 维的输出映射到 64 维的输出，第三个线性层将 64 维的输出映射到 10 维的输出，对应 10 个数字类别。\n",
    "* **`nn.ReLU` 模块：** 用于定义 ReLU 激活函数，它将输入数据中的负值转换为 0，并将正值保持不变。激活函数的作用是引入非线性，增强模型对数据特征的表达能力。\n",
    "\n",
    "通过定义这个 MLP 模型，代码准备好了用于处理 MNIST 数据集，并进行模型训练和预测。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceb841f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从训练数据加载器中获取一个 batch 的数据，并将其存储在 images 和 labels 变量中。\n",
    "images, labels = next(iter(trainloader)) \n",
    "\n",
    "# 从 images 中获取第一个图像的第一个通道的数据，并将其存储在 pixels 变量中。\n",
    "pixels = images[0][0] \n",
    "\n",
    "# 使用 Matplotlib 绘制图像。\n",
    "plt.imshow(pixels, cmap='gray') \n",
    "\n",
    "# 显示图像。\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f977a23",
   "metadata": {},
   "source": [
    "**解释：**\n",
    "\n",
    "这段代码从训练数据加载器中获取一个 batch 的数据，并显示第一个图像。\n",
    "\n",
    "* **`images, labels = next(iter(trainloader))`：** 这行代码从训练数据加载器 `trainloader` 中获取一个 batch 的数据，并将其存储在 `images` 和 `labels` 变量中。`images` 变量包含一个 batch 的图像数据（张量），`labels` 变量包含对应图像的标签数据（张量）。\n",
    "* **`pixels = images[0][0]`：** 这行代码从 `images` 变量中获取第一个图像的第一个通道的数据，并将其存储在 `pixels` 变量中。由于 MNIST 手写数字图像是一个灰度图像，因此每个图像只有一个通道。\n",
    "* **`plt.imshow(pixels, cmap='gray')`：** 这行代码使用 Matplotlib 的 `imshow` 函数显示从 `pixels` 变量中读取的图像数据，其中 `cmap='gray'` 指示使用灰度色板。\n",
    "* **`plt.show()`：** 这行代码显示图像。\n",
    "\n",
    "这段代码使用 Matplotlib 可视化了一个从 MNIST 数据集中读取的图像，帮助开发者理解数据格式，并为后续的模型训练提供直观参考。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43041754",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数，使用 PyTorch 的 nn.CrossEntropyLoss 模块，用于计算模型输出与真实标签之间的交叉熵损失。\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 将图像数据重新整理为一个二维张量，其中第一维度为 batch 大小，第二维度为每个图像的像素个数。\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# 将整理后的图像数据输入模型，获取模型的输出结果。\n",
    "output = model(images)\n",
    "\n",
    "# 使用损失函数计算模型输出与真实标签之间的交叉熵损失。\n",
    "loss = criterion(output, labels)\n",
    "\n",
    "# 定义优化器，使用 PyTorch 的 optim.Adam 模块，并设置学习率为 0.003。\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eac1889",
   "metadata": {},
   "source": [
    "**解释：**\n",
    "\n",
    "这段代码完成了模型训练中的一部分工作：计算损失并定义优化器。\n",
    "\n",
    "* **`criterion = nn.CrossEntropyLoss()`：**  定义了损失函数，使用 PyTorch 的 `nn.CrossEntropyLoss` 模块，它是一种常用的分类任务损失函数。交叉熵损失用于衡量模型输出的概率分布与真实标签分布之间的差异，目标是使模型输出的概率分布尽可能接近真实标签的分布。\n",
    "* **`images = images.view(images.shape[0], -1)`：**  将图像数据重新整理为一个二维张量，其中第一维度为 batch 大小，第二维度为每个图像的像素个数。这是为了将图像数据作为输入传递给模型。\n",
    "* **`output = model(images)`：**  将图像数据 `images` 输入到模型 `model` 中进行前向传播，并将模型的输出结果存储在 `output` 变量中。\n",
    "* **`loss = criterion(output, labels)`：** 使用交叉熵损失函数 `criterion` 计算模型输出 `output` 与真实标签 `labels` 之间的损失，并将其存储在 `loss` 变量中。\n",
    "* **`optimizer = optim.Adam(model.parameters(), lr=0.003)`：**  定义了优化器，使用 PyTorch 的 `optim.Adam` 模块，并设置学习率为 0.003。优化器的作用是根据损失函数的梯度信息来更新模型的参数，使得损失函数值不断下降，最终达到模型收敛的目的。\n",
    "\n",
    "这段代码完成了模型训练中的重要一步，计算了当前模型的损失，并定义了用于更新模型参数的优化器，为下一步的模型训练做准备。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819f72e3",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置训练的轮数为 15。\n",
    "epochs = 15 \n",
    "\n",
    "# 开始训练循环，循环执行 15 轮。\n",
    "for e in range(epochs): \n",
    "\n",
    "    # 初始化本轮训练的累计损失为 0。\n",
    "    running_loss = 0 \n",
    "\n",
    "    # 遍历训练数据加载器中的每个 batch 的数据。\n",
    "    for images, labels in trainloader: \n",
    "\n",
    "        # 将图像数据重新整理为二维张量，以便作为模型的输入。\n",
    "        images = images.view(images.shape[0], -1) \n",
    "\n",
    "        # 清除模型参数的梯度信息。\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        # 将图像数据输入模型，获取模型的输出。\n",
    "        output = model(images) \n",
    "\n",
    "        # 计算模型输出与真实标签之间的损失。\n",
    "        loss = criterion(output, labels) \n",
    "\n",
    "        # 反向传播计算损失函数对模型参数的梯度。\n",
    "        loss.backward() \n",
    "\n",
    "        # 根据梯度信息更新模型参数，并进行一步优化。\n",
    "        optimizer.step() \n",
    "\n",
    "        # 将当前 batch 的损失值累加到 running_loss 中。\n",
    "        running_loss += loss.item() \n",
    "\n",
    "    # 当遍历完一个 epoch 的所有数据后，打印本轮训练的平均损失。\n",
    "    else: \n",
    "\n",
    "        print(\"Epoch {} - 训练损失: {}\".format(e, running_loss/len(trainloader))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5e9ee6",
   "metadata": {},
   "source": [
    "**解释：**\n",
    "\n",
    "这段代码执行了一个简单的训练循环，训练神经网络模型 15 个 epoch。\n",
    "\n",
    "* **`epochs = 15`：**  设置训练的轮数为 15，表示模型将使用所有训练数据进行 15 轮训练。\n",
    "* **`for e in range(epochs)`：**  开始训练循环，循环执行 15 轮。\n",
    "* **`running_loss = 0`：** 初始化本轮训练的累计损失为 0。\n",
    "* **`for images, labels in trainloader`：**  遍历训练数据加载器中的每个 batch 的数据。\n",
    "* **`images = images.view(images.shape[0], -1)`：**  将图像数据重新整理为二维张量，以便作为模型的输入。\n",
    "* **`optimizer.zero_grad()`：** 清除模型参数的梯度信息，因为每个 batch 进行梯度下降之前需要先清除上一步的梯度信息。\n",
    "* **`output = model(images)`：**  将图像数据输入模型进行前向传播，获取模型的输出。\n",
    "* **`loss = criterion(output, labels)`：**  计算模型输出与真实标签之间的损失。\n",
    "* **`loss.backward()`：**  反向传播计算损失函数对模型参数的梯度。\n",
    "* **`optimizer.step()`：**  根据梯度信息更新模型参数，并进行一步优化。\n",
    "* **`running_loss += loss.item()`：** 将当前 batch 的损失值累加到 `running_loss` 中。\n",
    "* **`else:  print(\"Epoch {} - 训练损失: {}\".format(e, running_loss/len(trainloader)))`：**  当遍历完一个 epoch 的所有数据后，打印本轮训练的平均损失，以监控训练过程。\n",
    "\n",
    "这段代码展示了 PyTorch 中一个典型的训练循环，它演示了如何通过反复迭代地进行参数更新，从而实现模型的收敛，最终完成模型训练过程。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b738822d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个验证数据加载器，将所有验证数据作为一个 batch 加载到模型中，并启用数据随机打乱。\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=valset.data.shape[0], shuffle=True) \n",
    "\n",
    "# 从验证数据加载器中获取一个 batch 的数据，并将其存储在 val_images 和 val_labels 变量中。\n",
    "val_images, val_labels = next(iter(valloader)) \n",
    "\n",
    "# 将验证图像数据整理为一个二维张量，以便作为模型的输入。\n",
    "val_images = val_images.view(val_images.shape[0], -1) \n",
    "\n",
    "# 将验证图像数据输入模型，获取模型的输出结果。\n",
    "predictions = model (val_images) \n",
    "\n",
    "# 从模型输出结果中取出预测的标签，并将其存储在 predicted_labels 变量中。\n",
    "predicted_labels = np.argmax(predictions.detach().numpy(), axis=1) \n",
    "\n",
    "# 导入 sklearn 库的 accuracy_score 函数，用来计算模型的准确率。\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "# 计算模型在验证集上的准确率，并打印结果。\n",
    "accuracy_score(val_labels.detach().numpy(), predicted_labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdde390f",
   "metadata": {},
   "source": [
    "**解释：**\n",
    "\n",
    "这段代码使用训练好的模型对验证集进行评估，并打印模型在验证集上的准确率。\n",
    "\n",
    "* **`valloader = torch.utils.data.DataLoader(valset, batch_size=valset.data.shape[0], shuffle=True)`：**  创建了一个验证数据加载器，将所有验证数据作为一个 batch 加载到模型中，并启用数据随机打乱。\n",
    "* **`val_images, val_labels = next(iter(valloader))`：**  从验证数据加载器中获取一个 batch 的数据，并将其存储在 `val_images` 和 `val_labels` 变量中。\n",
    "* **`val_images = val_images.view(val_images.shape[0], -1)`：**  将验证图像数据整理为一个二维张量，以便作为模型的输入。\n",
    "* **`predictions = model (val_images)`：**  将验证图像数据输入模型，获取模型的输出结果。\n",
    "* **`predicted_labels = np.argmax(predictions.detach().numpy(), axis=1)`：**  从模型输出结果中取出预测的标签，并将其存储在 `predicted_labels` 变量中。这里使用 `np.argmax` 获取模型输出的概率分布中概率最大的类别，作为预测的标签。\n",
    "* **`from sklearn.metrics import accuracy_score`：**  导入 `sklearn` 库的 `accuracy_score` 函数，用来计算模型的准确率。\n",
    "* **`accuracy_score(val_labels.detach().numpy(), predicted_labels)`：**  计算模型在验证集上的准确率，并打印结果。\n",
    "\n",
    "这段代码展示了如何使用验证集评估训练好的模型，并使用 `sklearn.metrics.accuracy_score` 函数计算模型在验证集上的准确率，以便评估模型的泛化能力。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7809f262",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 PyTorch 的 torch.save 函数将训练好的模型保存到指定路径，模型文件名为 'my_mnist_model.pt'。\n",
    "torch.save(model, './model/my_mnist_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51db4483",
   "metadata": {},
   "source": [
    "**解释：**\n",
    "\n",
    "这段代码使用 `torch.save` 函数将训练好的模型 `model` 保存到磁盘上，以便在未来需要使用时加载并使用。\n",
    "\n",
    "* **`torch.save` 函数：**  PyTorch 的 `torch.save` 函数用于将模型、张量和其他 PyTorch 对象保存到磁盘。它提供了一个简单的方法来存储模型，以便在之后重新加载和使用。\n",
    "* **`model`：**  指的是训练好的模型，它包含了模型的结构和参数信息。\n",
    "* **`'./model/my_mnist_model.pt'`：**  是模型保存的路径和文件名。这里将模型保存到 `./model` 目录下，文件名叫做 `my_mnist_model.pt`。`pt` 是 PyTorch 模型的常用后缀名。\n",
    "\n",
    "通过使用 `torch.save` 函数保存模型，开发者就可以在之后需要使用模型的时候，使用 `torch.load` 函数加载模型，并在新的任务中使用该模型进行预测或进一步的训练。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d06922",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
